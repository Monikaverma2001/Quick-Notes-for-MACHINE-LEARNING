Define regression?
Machine Learning Regression is a technique for investigating the relationship between independent variables or features and a dependent variable or outcome. It’s used as a method for predictive modelling in machine learning, in which an algorithm is used to predict continuous outcomes.  


define regression line?
it is used to fit the data with the  best hyperplane which goes through the points.
A regression line indicates a linear relationship between the dependent variables on the y-axis and the independent variables on the x-axis. The correlation is established by analyzing the data pattern formed by the variables.
If Y is the dependent variable and X is the independent variable, the Y on X regression line equation is represented as follows:
 ‘Y = a + bX + ɛ.’
Y is the dependent variable.
a is the Y-intercept.
b is the slope of the regression line.
X is the independent variable.
ɛ is the residual (error).
error=actual-pridicted

b = (N∑XY-(∑X)(∑Y) / (N∑X^2– (∑X)^2) ;

And,

a = (∑Y – b ∑X) / N

Where N is the total number of observations.


What are the types of regression? 
There are a range of different approaches used in machine learning to perform regression. Different popular algorithms are used to achieve machine learning regression. The different techniques may include different numbers of independent variables or process different types of data. Distinct types of machine learning regression models may also assume a different relationship between the independent and dependent variables. For example, linear regression techniques assume that the relationship is linear, so wouldn’t be effective with datasets with nonlinear relationships.  

Some of the most common regression techniques in machine learning can be grouped into the following types of regression analysis: 

Simple Linear Regression 
Multiple linear regression 
Logistic regression 
